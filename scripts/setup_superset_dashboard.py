#!/usr/bin/env python3
"""Superset ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è‡ªå‹•ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯Supersetã«CI/CDãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’è‡ªå‹•ä½œæˆã—ã¾ã™ã€‚
å†ªç­‰æ€§: ä½•åº¦å®Ÿè¡Œã—ã¦ã‚‚åŒã˜çµæœã«ãªã‚Šã¾ã™ã€‚

ä½¿ç”¨æ–¹æ³•:
    docker exec nagare-superset python3 /app/scripts/setup_superset_dashboard.py
    docker exec nagare-superset python3 /app/scripts/setup_superset_dashboard.py --reset

ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
    --reset: æ—¢å­˜ã®ãƒãƒ£ãƒ¼ãƒˆã‚’å‰Šé™¤ã—ã¦ã‹ã‚‰å†ä½œæˆ

å‰ææ¡ä»¶:
    - PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨
    - SupersetãŒèµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨
    - superset/init_views.sql ãŒå®Ÿè¡Œæ¸ˆã¿ã§ã‚ã‚‹ã“ã¨
    - PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒSupersetã«ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã“ã¨
"""

import json
import sys


# ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ç®¡ç†ã™ã‚‹ãƒãƒ£ãƒ¼ãƒˆåã®ãƒªã‚¹ãƒˆ
MANAGED_CHARTS = [
    "å…¨ä½“æˆåŠŸç‡",
    "æœ€æ–°å®Ÿè¡Œå±¥æ­´",
    "å¤±æ•—ãŒå¤šã„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ Top10",
    "ãƒ–ãƒ©ãƒ³ãƒåˆ¥æˆåŠŸç‡",
    "ã‚½ãƒ¼ã‚¹ã‚µãƒãƒªãƒ¼",
    "æ—¥æ¬¡å®Ÿè¡Œæ•°",
    "æˆåŠŸç‡ãƒˆãƒ¬ãƒ³ãƒ‰",
    "æ™‚é–“å¸¯åˆ¥å®Ÿè¡Œæ•°",
    "ãƒ“ãƒ«ãƒ‰æ™‚é–“ãƒˆãƒ¬ãƒ³ãƒ‰",
    "MTTRã‚µãƒãƒªãƒ¼",
    "MTTRãƒˆãƒ¬ãƒ³ãƒ‰",
]


def setup_dashboard(reset: bool = False):
    """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹"""
    from superset.app import create_app

    app = create_app()
    with app.app_context():
        from superset import db
        from superset.connectors.sqla.models import SqlaTable
        from superset.models.core import Database
        from superset.models.dashboard import Dashboard
        from superset.models.slice import Slice

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å–å¾—
        database = db.session.query(Database).first()
        if not database:
            print("ERROR: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("Supersetã§å…ˆã«PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’ä½œæˆã—ã¦ãã ã•ã„")
            sys.exit(1)

        print(f"Using Database: {database.database_name} (ID: {database.id})")

        # ============================================================
        # Step 1: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç™»éŒ²
        # ============================================================
        print("\n=== Step 1: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç™»éŒ² ===")

        views = [
            # åŸºæœ¬ãƒ“ãƒ¥ãƒ¼
            "v_pipeline_overview",
            "v_recent_pipeline_runs",
            "v_failing_jobs",
            "v_branch_success_rate",
            # ã‚½ãƒ¼ã‚¹åˆ¥ãƒ“ãƒ¥ãƒ¼
            "v_source_summary",
            "v_daily_runs_by_source",
            "v_daily_success_rate_by_source",
            "v_hourly_runs_by_source",
            "v_daily_duration_by_source",
            # MTTRãƒ“ãƒ¥ãƒ¼
            "v_mttr",
            "v_daily_mttr",
        ]

        for view_name in views:
            existing = (
                db.session.query(SqlaTable)
                .filter_by(table_name=view_name, database_id=database.id)
                .first()
            )

            if existing:
                print(f"SKIP: {view_name} (already exists, ID: {existing.id})")
                continue

            table = SqlaTable(
                table_name=view_name, database_id=database.id, schema="public"
            )
            db.session.add(table)
            db.session.commit()
            print(f"CREATED: {view_name} (ID: {table.id})")

        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚«ãƒ©ãƒ ã‚’åŒæœŸ
        print("\n=== Syncing dataset columns ===")
        for table in db.session.query(SqlaTable).all():
            try:
                table.fetch_metadata()
                print(f"Synced: {table.table_name}")
            except Exception as e:
                print(f"Error syncing {table.table_name}: {e}")

        db.session.commit()

        # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆIDãƒãƒƒãƒ”ãƒ³ã‚°
        datasets = {t.table_name: t for t in db.session.query(SqlaTable).all()}

        # ============================================================
        # Step 2: ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆ
        # ============================================================
        print("\n=== Step 2: ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆ ===")

        dashboard = (
            db.session.query(Dashboard).filter_by(slug="cicd-performance").first()
        )
        if not dashboard:
            dashboard = Dashboard(
                dashboard_title="CI/CD ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
                slug="cicd-performance",
                published=True,
            )
            db.session.add(dashboard)
            db.session.commit()
            print(
                f"CREATED Dashboard: {dashboard.dashboard_title} (ID: {dashboard.id})"
            )
        else:
            print(f"EXISTS Dashboard: {dashboard.dashboard_title} (ID: {dashboard.id})")

        # ============================================================
        # Step 2.5: ãƒªã‚»ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€æ—¢å­˜ãƒãƒ£ãƒ¼ãƒˆã‚’å‰Šé™¤
        # ============================================================
        if reset:
            print("\n=== Reset Mode: æ—¢å­˜ãƒãƒ£ãƒ¼ãƒˆã‚’å‰Šé™¤ ===")
            for chart_name in MANAGED_CHARTS:
                existing = (
                    db.session.query(Slice).filter_by(slice_name=chart_name).first()
                )
                if existing:
                    db.session.delete(existing)
                    print(f"DELETED: {chart_name}")
            db.session.commit()

        # ============================================================
        # Step 3: ãƒãƒ£ãƒ¼ãƒˆä½œæˆ/æ›´æ–°
        # ============================================================
        print("\n=== Step 3: ãƒãƒ£ãƒ¼ãƒˆä½œæˆ/æ›´æ–° ===")

        charts_config = [
            # === åŸºæœ¬æŒ‡æ¨™ ===
            {
                "slice_name": "å…¨ä½“æˆåŠŸç‡",
                "viz_type": "big_number_total",
                "datasource": datasets["v_pipeline_overview"],
                "params": {
                    "viz_type": "big_number_total",
                    "metric": {
                        "expressionType": "SIMPLE",
                        "column": {
                            "column_name": "overall_success_rate",
                            "type": "NUMERIC",
                        },
                        "aggregate": "AVG",
                        "label": "Success Rate",
                    },
                    "subheader": "% å…¨ãƒªãƒã‚¸ãƒˆãƒªå¹³å‡",
                    "y_axis_format": ".1f",
                },
            },
            {
                "slice_name": "æœ€æ–°å®Ÿè¡Œå±¥æ­´",
                "viz_type": "table",
                "datasource": datasets["v_recent_pipeline_runs"],
                "params": {
                    "viz_type": "table",
                    "query_mode": "aggregate",
                    "groupby": [
                        "source",
                        "repository_name",
                        "pipeline_name",
                        "status",
                        "branch_name",
                        "started_at",
                        "duration_sec",
                    ],
                    "metrics": [],
                    "percent_metrics": [],
                    "row_limit": 50,
                    "include_time": False,
                    "order_desc": True,
                    "show_cell_bars": False,
                    "table_timestamp_format": "smart_date",
                },
            },
            {
                "slice_name": "å¤±æ•—ãŒå¤šã„ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ Top10",
                "viz_type": "table",
                "datasource": datasets["v_failing_jobs"],
                "params": {
                    "viz_type": "table",
                    "query_mode": "aggregate",
                    "groupby": [
                        "repository_name",
                        "pipeline_name",
                        "failure_count",
                        "failure_rate",
                        "total_runs",
                    ],
                    "metrics": [],
                    "row_limit": 10,
                    "order_desc": True,
                    "show_cell_bars": True,
                },
            },
            {
                "slice_name": "ãƒ–ãƒ©ãƒ³ãƒåˆ¥æˆåŠŸç‡",
                "viz_type": "dist_bar",
                "datasource": datasets["v_branch_success_rate"],
                "params": {
                    "viz_type": "dist_bar",
                    "metrics": [
                        {
                            "expressionType": "SIMPLE",
                            "column": {
                                "column_name": "success_rate",
                                "type": "NUMERIC",
                            },
                            "aggregate": "AVG",
                            "label": "AVG(success_rate)",
                        }
                    ],
                    "groupby": ["branch_type"],
                    "columns": [],
                    "row_limit": 20,
                    "color_scheme": "supersetColors",
                    "show_legend": False,
                    "y_axis_format": ",.1f",
                },
            },
            # === ã‚½ãƒ¼ã‚¹åˆ¥æŒ‡æ¨™ï¼ˆGitHub / Bitrise / Xcode Cloudï¼‰ ===
            {
                "slice_name": "ã‚½ãƒ¼ã‚¹ã‚µãƒãƒªãƒ¼",
                "viz_type": "table",
                "datasource": datasets["v_source_summary"],
                "params": {
                    "viz_type": "table",
                    "query_mode": "aggregate",
                    "groupby": [
                        "source",
                        "total_runs",
                        "success_count",
                        "failure_count",
                        "success_rate",
                        "avg_duration_sec",
                    ],
                    "metrics": [],
                    "row_limit": 10,
                    "order_desc": True,
                    "show_cell_bars": True,
                },
            },
            {
                "slice_name": "æ—¥æ¬¡å®Ÿè¡Œæ•°",
                "viz_type": "echarts_timeseries_bar",
                "datasource": datasets["v_daily_runs_by_source"],
                "params": {
                    "viz_type": "echarts_timeseries_bar",
                    "x_axis": "run_date",
                    "time_grain_sqla": "P1D",
                    "metrics": [
                        {
                            "expressionType": "SIMPLE",
                            "column": {"column_name": "run_count", "type": "BIGINT"},
                            "aggregate": "SUM",
                            "label": "SUM(run_count)",
                        }
                    ],
                    "groupby": ["source"],
                    "row_limit": 10000,
                    "stack": "Stack",
                    "only_total": False,
                    "color_scheme": "supersetColors",
                    "show_legend": True,
                    "legendType": "scroll",
                    "legendOrientation": "top",
                    "rich_tooltip": True,
                    "tooltipTimeFormat": "smart_date",
                    "x_axis_time_format": "smart_date",
                },
            },
            {
                "slice_name": "æˆåŠŸç‡ãƒˆãƒ¬ãƒ³ãƒ‰",
                "viz_type": "echarts_timeseries_line",
                "datasource": datasets["v_daily_success_rate_by_source"],
                "params": {
                    "viz_type": "echarts_timeseries_line",
                    "x_axis": "run_date",
                    "metrics": [
                        {
                            "expressionType": "SIMPLE",
                            "column": {
                                "column_name": "success_rate",
                                "type": "NUMERIC",
                            },
                            "aggregate": "AVG",
                            "label": "AVG(success_rate)",
                        }
                    ],
                    "groupby": ["source"],
                    "row_limit": 10000,
                    "color_scheme": "supersetColors",
                    "show_legend": True,
                    "rich_tooltip": True,
                },
            },
            {
                "slice_name": "æ™‚é–“å¸¯åˆ¥å®Ÿè¡Œæ•°",
                "viz_type": "echarts_timeseries_bar",
                "datasource": datasets["v_hourly_runs_by_source"],
                "params": {
                    "viz_type": "echarts_timeseries_bar",
                    "x_axis": "hour_of_day",
                    "x_axis_sort": "hour_of_day",
                    "x_axis_sort_asc": True,
                    "metrics": [
                        {
                            "expressionType": "SIMPLE",
                            "column": {"column_name": "run_count", "type": "BIGINT"},
                            "aggregate": "SUM",
                            "label": "SUM(run_count)",
                        }
                    ],
                    "groupby": ["source"],
                    "row_limit": 100,
                    "stack": "Stack",
                    "color_scheme": "supersetColors",
                    "show_legend": True,
                    "rich_tooltip": True,
                },
            },
            {
                "slice_name": "ãƒ“ãƒ«ãƒ‰æ™‚é–“ãƒˆãƒ¬ãƒ³ãƒ‰",
                "viz_type": "echarts_timeseries_line",
                "datasource": datasets["v_daily_duration_by_source"],
                "params": {
                    "viz_type": "echarts_timeseries_line",
                    "x_axis": "run_date",
                    "metrics": [
                        {
                            "expressionType": "SIMPLE",
                            "column": {
                                "column_name": "avg_duration_sec",
                                "type": "NUMERIC",
                            },
                            "aggregate": "AVG",
                            "label": "AVG(avg_duration_sec)",
                        }
                    ],
                    "groupby": ["source"],
                    "row_limit": 10000,
                    "color_scheme": "supersetColors",
                    "show_legend": True,
                    "rich_tooltip": True,
                    "y_axis_format": ",.0f",
                },
            },
            # === MTTRæŒ‡æ¨™ ===
            {
                "slice_name": "MTTRã‚µãƒãƒªãƒ¼",
                "viz_type": "table",
                "datasource": datasets["v_mttr"],
                "params": {
                    "viz_type": "table",
                    "query_mode": "aggregate",
                    "groupby": [
                        "repository_name",
                        "source",
                        "failure_count",
                        "recovered_count",
                        "avg_mttr_minutes",
                        "min_mttr_minutes",
                        "max_mttr_minutes",
                    ],
                    "metrics": [],
                    "row_limit": 20,
                    "order_desc": True,
                    "show_cell_bars": True,
                },
            },
            {
                "slice_name": "MTTRãƒˆãƒ¬ãƒ³ãƒ‰",
                "viz_type": "echarts_timeseries_line",
                "datasource": datasets["v_daily_mttr"],
                "params": {
                    "viz_type": "echarts_timeseries_line",
                    "x_axis": "run_date",
                    "metrics": [
                        {
                            "expressionType": "SIMPLE",
                            "column": {
                                "column_name": "avg_mttr_minutes",
                                "type": "NUMERIC",
                            },
                            "aggregate": "AVG",
                            "label": "AVG(avg_mttr_minutes)",
                        }
                    ],
                    "groupby": ["source"],
                    "row_limit": 10000,
                    "color_scheme": "supersetColors",
                    "show_legend": True,
                    "rich_tooltip": True,
                    "y_axis_format": ",.0f",
                },
            },
        ]

        slices = []
        for chart in charts_config:
            ds = chart["datasource"]
            params = chart["params"].copy()
            params["datasource"] = f"{ds.id}__table"

            existing = (
                db.session.query(Slice).filter_by(slice_name=chart["slice_name"]).first()
            )
            if existing:
                # æ—¢å­˜ãƒãƒ£ãƒ¼ãƒˆã‚’æ›´æ–°ï¼ˆå†ªç­‰æ€§ï¼‰
                existing.viz_type = chart["viz_type"]
                existing.datasource_id = ds.id
                existing.datasource_type = "table"
                existing.params = json.dumps(params)
                db.session.commit()
                slices.append(existing)
                print(f'UPDATED Chart: {chart["slice_name"]} (ID: {existing.id})')
                continue

            # æ–°è¦ãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ
            slice_obj = Slice(
                slice_name=chart["slice_name"],
                viz_type=chart["viz_type"],
                datasource_id=ds.id,
                datasource_type="table",
                params=json.dumps(params),
            )
            db.session.add(slice_obj)
            db.session.commit()
            slices.append(slice_obj)
            print(f'CREATED Chart: {chart["slice_name"]} (ID: {slice_obj.id})')

        # ============================================================
        # Step 4: ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã«ãƒãƒ£ãƒ¼ãƒˆã‚’é–¢é€£ä»˜ã‘
        # ============================================================
        print("\n=== Step 4: ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã«ãƒãƒ£ãƒ¼ãƒˆã‚’é–¢é€£ä»˜ã‘ ===")

        dashboard.slices = slices

        # ã‚¯ãƒ­ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’æœ‰åŠ¹åŒ–
        metadata = json.loads(dashboard.json_metadata) if dashboard.json_metadata else {}
        metadata["cross_filters_enabled"] = True
        metadata["chart_configuration"] = {}
        for s in slices:
            metadata["chart_configuration"][str(s.id)] = {
                "id": s.id,
                "crossFilters": {
                    "scope": "global",
                    "chartsInScope": [x.id for x in slices if x.id != s.id],
                },
            }
        dashboard.json_metadata = json.dumps(metadata)

        db.session.commit()
        print(f"Dashboard updated with {len(slices)} charts")
        print("Cross-filtering enabled")

        # ============================================================
        # å®Œäº†
        # ============================================================
        print("\n" + "=" * 60)
        print("âœ… ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†!")
        print("=" * 60)
        print(f"\nãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰URL:")
        print(f"  http://localhost:8088/superset/dashboard/{dashboard.slug}/")
        print("\næ³¨æ„: ãƒãƒ£ãƒ¼ãƒˆã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã¯ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç·¨é›†ç”»é¢ã§èª¿æ•´ã—ã¦ãã ã•ã„")


if __name__ == "__main__":
    reset_mode = "--reset" in sys.argv
    if reset_mode:
        print("ğŸ”„ Reset mode enabled: æ—¢å­˜ãƒãƒ£ãƒ¼ãƒˆã‚’å‰Šé™¤ã—ã¦å†ä½œæˆã—ã¾ã™")
    setup_dashboard(reset=reset_mode)
